{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                input_: ndarray):\n",
    "        self.input_ = input_\n",
    "\n",
    "        self.output = self._output()\n",
    "\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    def backward(self, output_grad: ndarray) -> ndarray:\n",
    "\n",
    "        assert_same_shape(self.output, output_grad)\n",
    "\n",
    "        self._compute_grads(output_grad)\n",
    "\n",
    "        assert_same_shape(self.input_, self.input_grad)\n",
    "        return self.input_grad\n",
    "\n",
    "\n",
    "    def _compute_grads(self, output_grad: ndarray) -> ndarray:\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "\n",
    "\n",
    "    def _output(self, input_: ndarray) -> ndarray:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamOperation(Operation):\n",
    "\n",
    "    def __init__(self, param: ndarray) -> ndarray:\n",
    "        super().__init__()\n",
    "        self.param = param\n",
    "\n",
    "    def backward(self, output_grad: ndarray) -> ndarray:\n",
    "\n",
    "        assert_same_shape(self.output, output_grad)\n",
    "\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "        self.param_grad = self._param_grad(output_grad)\n",
    "\n",
    "        assert_same_shape(self.inputs, self.input_grad)\n",
    "\n",
    "        return self.input_grad\n",
    "\n",
    "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "\n",
    "    def __init__(self, W: ndarray):\n",
    "        super().__init__(W)\n",
    "\n",
    "    def _outputs(self) -> ndarray:\n",
    "        return np.dot(self.input, self.param)\n",
    "\n",
    "    def _input_grads(self, output_grad: ndarray) -> ndarray:\n",
    "        return np.dot(output_grad, np.transpose(self.param, (1, 0)))\n",
    "\n",
    "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        return np.dot(np.transpose(self.input, (1, 0)), output_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "print(a)\n",
    "print(b)\n",
    "b = np.array([5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasAdd(ParamOperation):\n",
    "\n",
    "    def __init__(self,\n",
    "                 B: ndarray):\n",
    "        \n",
    "        assert B.shape[0] == 1\n",
    "        \n",
    "        super().__init__(B)\n",
    "\n",
    "    def _outputs(self) -> ndarray:\n",
    "        \n",
    "        # self.input.shape[1] == self.param.shape[1]\n",
    "        return self.input + self.param\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        \n",
    "        # self.input.shape[1] == self.param.shape[1]\n",
    "        return np.ones_like(self.input) * output_grad\n",
    "\n",
    "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        param_grad = torch.ones_like(self.param) * output_grad\n",
    "        return np.sum(param_grad, axis=0).reshape(1, param_grad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 neurons: int) -> None:\n",
    "        self.neurons = neurons\n",
    "        self.first = True\n",
    "        self.params: List[ndarray] = []\n",
    "        self.param_grads: List[ndarray] = []\n",
    "        self.operations: List[Operation] = []\n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_: ndarray) -> ndarray:\n",
    "        if self.first:\n",
    "            self._setup_layer(input_)\n",
    "            self.first = False\n",
    "\n",
    "        self.input_ = input_\n",
    "\n",
    "        for operation in self.operations:\n",
    "\n",
    "            input_ = operation.forward(input_)\n",
    "\n",
    "        self.output = input_\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_grad: ndarray) -> ndarray:\n",
    "\n",
    "        assert_same_shapes(self.output, output_grad)\n",
    "\n",
    "        for operation in reversed(self.operations):\n",
    "            output_grad = operation.backward(output_grad)\n",
    "\n",
    "        input_grad = output_grad\n",
    "\n",
    "        assert_same_shapes(self.input_, input_grad)\n",
    "\n",
    "        return input_grad\n",
    "\n",
    "    def _param_grads(self) -> ndarray:\n",
    "\n",
    "        self.param_grads = []\n",
    "        for operation in self.operations:\n",
    "            if issubclass(operation.__class__, ParamOperation):\n",
    "                self.param_grads.append(operation.param_grad)\n",
    "\n",
    "    def _params(self) -> ndarray:\n",
    "\n",
    "        self.params = []\n",
    "        for operation in self.operations:\n",
    "            if issubclass(operation.__class__, ParamOperation):\n",
    "                self.params.append(operation.param)\n",
    "\n",
    "\n",
    "    def update_params(self,\n",
    "                      learning_rate: float) -> None:\n",
    "\n",
    "        for param, param_grad in zip(self.params, self.param_grads):\n",
    "            param -= learning_rate * param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, prediction: ndarray, target: ndarray) -> float:\n",
    "\n",
    "        assert_same_shapes(prediction, target)\n",
    "\n",
    "        self.prediction = prediction\n",
    "        self.target = target\n",
    "\n",
    "        self.output = self._output()\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self) -> ndarray:\n",
    "\n",
    "        self.input_grad = self._input_grad()\n",
    "\n",
    "        assert_same_shapes(self.prediction, self.input_grad)\n",
    "\n",
    "        return self.input_grad\n",
    "\n",
    "    def _output(self) -> float:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _input_grad(self) -> ndarray:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(Loss):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def _output(self) -> float:\n",
    "\n",
    "        loss = np.sum(np.power(self.prediction - self.target, 2))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _input_grad(self) -> ndarray:\n",
    "\n",
    "        return 2.0 * (self.prediction - self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self, layers: List[Layer],\n",
    "                 loss: Loss,\n",
    "                 learning_rate: float = 0.01) -> None:\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x_batch: ndarray) -> ndarray:\n",
    "\n",
    "        x_out = x_batch\n",
    "        for layer in self.layers:\n",
    "            x_out = layer.forward(x_out)\n",
    "\n",
    "        return x_out\n",
    "\n",
    "    def batch_loss(self,\n",
    "                   prediction: ndarray,\n",
    "                   y_batch: ndarray) -> ndarray:\n",
    "\n",
    "        assert_same_shape(prediction, y_batch)\n",
    "\n",
    "        return self.loss.loss_gradient(prediction, y_batch)\n",
    "\n",
    "    def backward(self, loss_grad: ndarray) -> None:\n",
    "\n",
    "        grad = loss_grad\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def train_batch(self,\n",
    "                    x_batch: ndarray,\n",
    "                    y_batch: ndarray) -> float:\n",
    "\n",
    "        assert x_batch.shape[0] == y_batch.shape[0]\n",
    "        \n",
    "        predictions = self.forward(x_batch)\n",
    "\n",
    "        loss = self.loss.forward(predictions, y_batch)\n",
    "\n",
    "        self.backward(self.loss.backward(predictions, y_batch))\n",
    "\n",
    "        self.update_params()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def update_params(self) -> None:\n",
    "        for layer in self.layers:\n",
    "            layer.update_params(self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
