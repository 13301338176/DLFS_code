{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains experiments for:\n",
    "\n",
    "* Loss functions\n",
    "* Learning rate decay\n",
    "* Weight initialization\n",
    "* Optimizers\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lincoln imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln\n",
    "from lincoln.numpy.layers import Dense\n",
    "from lincoln.numpy.losses import SoftmaxCrossEntropy, MeanSquaredError, SoftmaxCrossEntropyComplex\n",
    "from lincoln.numpy.optimizers import Optimizer, SGD, SGDMomentum\n",
    "from lincoln.numpy.activations import Sigmoid, Tanh, Linear, ReLU\n",
    "from lincoln.numpy.network import NeuralNetwork\n",
    "from lincoln.numpy.train import Trainer\n",
    "from lincoln.data import mnist\n",
    "from lincoln.np_utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(y_train)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of MNIST Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scaled to mean 0, variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-33.318421449829934,\n",
       " 221.68157855017006,\n",
       " -33.318421449829934,\n",
       " 221.68157855017006)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.424073894391566, 2.821543345689335, -0.424073894391566, 2.821543345689335)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''The model validation accuracy is: \n",
    "    {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.611\n",
      "Validation loss after 20 epochs is 0.428\n",
      "Validation loss after 30 epochs is 0.389\n",
      "Validation loss after 40 epochs is 0.374\n",
      "Validation loss after 50 epochs is 0.366\n",
      "The model validation accuracy is: 72.58%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=False), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.952\n",
      "Loss increased after epoch 20, final loss was 0.952, using the model from epoch 10\n",
      "The model validation accuracy is: 41.73%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(normalize=True), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.630\n",
      "Validation loss after 20 epochs is 0.574\n",
      "Validation loss after 30 epochs is 0.549\n",
      "Validation loss after 40 epochs is 0.546\n",
      "Loss increased after epoch 50, final loss was 0.546, using the model from epoch 40\n",
      "\n",
      "The model validation accuracy is: \n",
      "    91.01%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "print()\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.441\n",
      "Validation loss after 20 epochs is 0.351\n",
      "Validation loss after 30 epochs is 0.345\n",
      "Validation loss after 40 epochs is 0.338\n",
      "Loss increased after epoch 50, final loss was 0.338, using the model from epoch 40\n",
      "The model validation accuracy is: 95.51%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optim = SGD(0.1)\n",
    "\n",
    "optim = SGDMomentum(0.1, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.372\n",
      "Validation loss after 20 epochs is 0.305\n",
      "Validation loss after 30 epochs is 0.290\n",
      "Loss increased after epoch 40, final loss was 0.290, using the model from epoch 30\n",
      "The model validation accuracy is: \n",
      "    95.69%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.15, momentum=0.9, final_lr = 0.05, decay_type='linear'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.468\n",
      "Validation loss after 20 epochs is 0.319\n",
      "Validation loss after 30 epochs is 0.290\n",
      "Loss increased after epoch 40, final loss was 0.290, using the model from epoch 30\n",
      "The model validation accuracy is: \n",
      "    95.74%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear())],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20190119,\n",
    "            batch_size=60);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.321\n",
      "Validation loss after 20 epochs is 0.260\n",
      "Loss increased after epoch 30, final loss was 0.260, using the model from epoch 20\n",
      "The model validation accuracy is: \n",
      "    95.75%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.15, momentum=0.9, final_lr = 0.05, decay_type='linear')\n",
    "\n",
    "trainer = Trainer(mnist_soft, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.410\n",
      "Validation loss after 20 epochs is 0.261\n",
      "Validation loss after 30 epochs is 0.244\n",
      "Loss increased after epoch 40, final loss was 0.244, using the model from epoch 30\n",
      "The model validation accuracy is: \n",
      "    96.52%\n"
     ]
    }
   ],
   "source": [
    "mnist_soft = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(mnist_soft, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.312\n",
      "Validation loss after 20 epochs is 0.233\n",
      "Validation loss after 30 epochs is 0.221\n",
      "Validation loss after 40 epochs is 0.209\n",
      "Loss increased after epoch 50, final loss was 0.209, using the model from epoch 40\n",
      "The model validation accuracy is: \n",
      "    96.69%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning, with and without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.296\n",
      "Validation loss after 20 epochs is 0.243\n",
      "Validation loss after 30 epochs is 0.225\n",
      "Validation loss after 40 epochs is 0.203\n",
      "Validation loss after 50 epochs is 0.186\n",
      "The model validation accuracy is: \n",
      "    97.15%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.296\n",
      "Validation loss after 20 epochs is 0.243\n",
      "Validation loss after 30 epochs is 0.225\n",
      "Validation loss after 40 epochs is 0.203\n",
      "Validation loss after 50 epochs is 0.186\n",
      "The model validation accuracy is: \n",
      "    97.15%\n"
     ]
    }
   ],
   "source": [
    "mnist_soft = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(mnist_soft, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.373\n",
      "Validation loss after 20 epochs is 0.344\n",
      "Validation loss after 30 epochs is 0.295\n",
      "Validation loss after 40 epochs is 0.287\n",
      "Validation loss after 50 epochs is 0.274\n",
      "Validation loss after 60 epochs is 0.268\n",
      "Validation loss after 70 epochs is 0.250\n",
      "Validation loss after 80 epochs is 0.247\n",
      "Validation loss after 90 epochs is 0.247\n",
      "Validation loss after 100 epochs is 0.241\n",
      "The model validation accuracy is: \n",
      "    96.40%\n"
     ]
    }
   ],
   "source": [
    "mnist_soft = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.5),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.5),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(mnist_soft, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 0.517\n",
      "Validation loss after 20 epochs is 0.334\n",
      "Validation loss after 30 epochs is 0.249\n",
      "Validation loss after 40 epochs is 0.247\n",
      "Loss increased after epoch 50, final loss was 0.247, using the model from epoch 40\n",
      "The model validation accuracy is: \n",
      "    95.98%\n"
     ]
    }
   ],
   "source": [
    "mnist_soft = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(mnist_soft, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 50,\n",
    "       eval_every = 10,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model, 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2459572910091175\n",
      "10 3.0664165533972625\n",
      "20 1.7275436661304933\n",
      "30 1.222254129130674\n",
      "40 0.750363636816075\n",
      "50 0.6610351600420998\n",
      "60 1.162050793195217\n",
      "70 0.4025496603492532\n",
      "80 0.5224687796768276\n",
      "90 0.7927112829708989\n",
      "100 0.46852054351815864\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    83.23%\n",
      "110 0.6904234010572262\n",
      "120 0.5450971863939684\n",
      "130 0.8392732860525914\n",
      "140 0.4926345407538619\n",
      "150 0.4977110330444994\n",
      "160 0.562031598100105\n",
      "170 0.23128330349960383\n",
      "180 0.9229771764001745\n",
      "190 0.6285661107097584\n",
      "200 0.4830428161357536\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    89.47%\n",
      "210 0.1635097917598027\n",
      "220 0.3101699306819837\n",
      "230 0.5915025578652312\n",
      "240 0.44144427641633366\n",
      "250 0.7103041237379478\n",
      "260 0.6281740777786917\n",
      "270 0.5054715704703846\n",
      "280 0.5827667541204994\n",
      "290 0.22115550543592144\n",
      "300 0.3860174726326829\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    89.77%\n",
      "310 0.3239039459693302\n",
      "320 0.5982687330002361\n",
      "330 0.4171953479358219\n",
      "340 0.9317228718444579\n",
      "350 0.6667104104186454\n",
      "360 0.4885225677325336\n",
      "370 0.657774528199964\n",
      "380 0.681563962871154\n",
      "390 0.6093648386073747\n",
      "400 0.5740383734633514\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    90.31%\n",
      "410 0.3455460363764509\n",
      "420 0.25422524667459456\n",
      "430 0.2572481876443191\n",
      "440 0.6271350899953014\n",
      "450 0.4830859251187056\n",
      "460 0.28047616461490926\n",
      "470 0.36325221705495586\n",
      "480 0.48053927720229933\n",
      "490 0.4315430603068055\n",
      "500 0.4763522231452251\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    90.14%\n",
      "510 0.38512094752543313\n",
      "520 0.6948857684205995\n",
      "530 0.5591497992704049\n",
      "540 0.7311833037929728\n",
      "550 0.45549174715675517\n",
      "560 0.3181076666975217\n",
      "570 0.22962961802409182\n",
      "580 0.5388735122760234\n",
      "590 0.39491581121247715\n",
      "600 0.25118798085289934\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    91.19%\n",
      "610 0.9089854215841908\n",
      "620 0.20664469354004003\n",
      "630 0.7707850581038996\n",
      "640 0.4482855320753772\n",
      "650 0.2807156081154671\n",
      "660 0.3607370347576719\n",
      "670 0.6779415778415046\n",
      "680 0.4061218382339664\n",
      "690 0.8247454016412874\n",
      "700 0.8383942404817225\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    91.40%\n",
      "710 0.2612765381524664\n",
      "720 0.42882844000783493\n",
      "730 0.20357563440868348\n",
      "740 0.3533841667430194\n",
      "750 0.841536556322774\n",
      "760 0.9476081727071382\n",
      "770 0.2936443791290739\n",
      "780 0.3129001777381552\n",
      "790 0.5346744871034527\n",
      "800 0.6159160281439021\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    91.04%\n",
      "810 0.4848436698678045\n",
      "820 0.5238083838407729\n",
      "830 0.5733161784035633\n",
      "840 0.38380922579721727\n",
      "850 0.6859637552119527\n",
      "860 0.333223887594078\n",
      "870 0.4272239857751116\n",
      "880 0.2688278988507301\n",
      "890 0.31577309672391285\n",
      "900 0.6190234178949988\n",
      "Evaluating on test set...\n",
      "The model validation accuracy is:\n",
      "                    91.52%\n",
      "910 0.28237258242388197\n",
      "920 0.3142649213668091\n",
      "930 0.47734014814280895\n",
      "940 0.5394445944278881\n",
      "950 0.3844735344635816\n",
      "960 0.28891421456715705\n",
      "970 0.6867875538966809\n",
      "980 0.3565355181929933\n",
      "990 0.46311283868945435\n",
      "Validation loss after 1 epochs is 0.535\n",
      "The model validation accuracy is: \n",
      "    90.37%\n"
     ]
    }
   ],
   "source": [
    "mnist_soft = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(mnist_soft, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 1,\n",
    "       eval_every = 1,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "100 The model validation accuracy is:\n",
      "                    87.86%\n",
      "Evaluating on test set...\n",
      "200 The model validation accuracy is:\n",
      "                    91.03%\n",
      "Evaluating on test set...\n",
      "300 The model validation accuracy is:\n",
      "                    92.43%\n",
      "Evaluating on test set...\n",
      "400 The model validation accuracy is:\n",
      "                    93.29%\n",
      "Evaluating on test set...\n",
      "500 The model validation accuracy is:\n",
      "                    93.60%\n",
      "Evaluating on test set...\n",
      "600 The model validation accuracy is:\n",
      "                    93.82%\n",
      "Evaluating on test set...\n",
      "700 The model validation accuracy is:\n",
      "                    94.30%\n",
      "Evaluating on test set...\n",
      "800 The model validation accuracy is:\n",
      "                    94.61%\n",
      "Evaluating on test set...\n",
      "900 The model validation accuracy is:\n",
      "                    93.91%\n",
      "Validation loss after 1 epochs is 0.333\n",
      "The model validation accuracy is: \n",
      "    94.44%\n"
     ]
    }
   ],
   "source": [
    "mnist_soft = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20190119)\n",
    "\n",
    "trainer = Trainer(mnist_soft, SGDMomentum(0.1, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels,\n",
    "       epochs = 1,\n",
    "       eval_every = 1,\n",
    "       seed=20190119,\n",
    "           batch_size=60,\n",
    "           early_stopping=True);\n",
    "\n",
    "calc_accuracy_model(mnist_soft, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
