{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frameworks:\n",
    "\n",
    "* PyTorch first pass\n",
    "    * `Model` with `forward` method.\n",
    "    * Manual training loop\n",
    "* PyTorch second pass\n",
    "    * `Model` with `forward` method.\n",
    "    * `Trainer` class that takes in:\n",
    "        * `Model`\n",
    "        * `Optimizer`\n",
    "        * `_Loss`\n",
    "\n",
    "Models:\n",
    "\n",
    "* Boston dataset (used for testing)\n",
    "* MNIST Conv net\n",
    "* LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[3., 3.,],\n",
    "                  [3., 3.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from typing import Tuple, List\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from lincoln.pytorch.layers import PyTorchLayer\n",
    "from lincoln.pytorch.model import PyTorchModel\n",
    "from lincoln.pytorch.train import PyTorchTrainer\n",
    "from lincoln.pytorch.preprocessor import ConvNetPreprocessor\n",
    "from lincoln.pytorch.utils import assert_dim, permute_data\n",
    "\n",
    "torch.manual_seed(20190325);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Trainer` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Boston model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonModel(PyTorchModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 13,\n",
    "                 hidden_dropout: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = DenseLayer(13, hidden_size, \n",
    "                                 activation=nn.Tanh(),\n",
    "                                 dropout = hidden_dropout)\n",
    "        self.dense2 = DenseLayer(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        \n",
    "        assert_dim(x, 2)\n",
    "        \n",
    "        assert x.shape[1] == 13\n",
    "\n",
    "        x = self.dense1(x, inference)\n",
    "        return self.dense2(x, inference),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, optimizer, loss\n",
    "pytorch_boston_model = BostonModel(hidden_size=13, hidden_dropout=0.8)\n",
    "optimizer = optim.SGD(pytorch_boston_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 0 epochs was 409.20794677734375\n",
      "The loss after 10 epochs was 27.483047485351562\n",
      "The loss after 20 epochs was 20.87213897705078\n",
      "The loss after 30 epochs was 21.018001556396484\n",
      "The loss after 40 epochs was 19.883886337280273\n",
      "The loss after 50 epochs was 18.254472732543945\n",
      "The loss after 60 epochs was 17.96509552001953\n",
      "The loss after 70 epochs was 16.910072326660156\n",
      "The loss after 80 epochs was 19.397686004638672\n",
      "The loss after 90 epochs was 16.579086303710938\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(pytorch_boston_model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs=100,\n",
    "            eval_every=10,\n",
    "            final_lr_exp = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.961467742919922"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.pow(pytorch_boston_model(X_test, inference=True)[0] - y_test, 2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pytorch_boston_model(X_test)[0].view(-1)\n",
    "test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred.detach().numpy()\n",
    "test_actual = test_actual.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x122cc8b70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(test_pred, test_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first show an example using `DataLoader`s, and then show one without using `DataLoader`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1305,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/data.html\n",
    "train_dataset = MNIST(root='../mnist_data/',\n",
    "                      train=True, \n",
    "                      download=True,\n",
    "                      transform=img_transforms)\n",
    "\n",
    "test_dataset = MNIST(root='../mnist_data/',\n",
    "                     train=False, \n",
    "                     download=True,\n",
    "                     transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=60, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=60, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, filter_size, \n",
    "                              padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.conv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_ConvNet(PyTorchModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh(),\n",
    "                               dropout=0.8)\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True,\n",
    "                               dropout=0.8)\n",
    "        self.dense1 = DenseLayer(28 * 28 * 7, 32, activation=nn.Tanh(),\n",
    "                                 dropout=0.8)\n",
    "        self.dense2 = DenseLayer(32, 10)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using only `Dataloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(train_dataloader = train_loader,        \n",
    "            test_dataloader = test_loader,\n",
    "            epochs=1,\n",
    "            eval_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy using only the `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model):\n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    for ii, (X_batch, y_batch) in enumerate(test_loader):\n",
    "        output = model(X_batch)[0]\n",
    "        accuracy_batch = (torch.max(output, dim=1)[1] == y_batch).type(torch.float32).mean().item()\n",
    "        accuracies.append(accuracy_batch)\n",
    "    return torch.Tensor(accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without using `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ((train_dataset.train_data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081\n",
    "mnist_test = ((test_dataset.test_data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train.min(), mnist_train.max(), mnist_test.min(), mnist_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train=mnist_train, y_train=train_dataset.train_labels, \n",
    "            X_test=mnist_test, y_test=test_dataset.test_labels,     \n",
    "            epochs=1,\n",
    "            eval_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_no_dataloader(model, mnist_test):\n",
    "    model.eval()\n",
    "    output = model(mnist_test)[0]\n",
    "    return (torch.max(output, dim=1)[1] == test_dataset.test_labels).type(torch.float32).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_no_dataloader(model, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~98% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working backwards:\n",
    "\n",
    "* Want a character level model - predict next char."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to do it?\n",
    "\n",
    "Pass in sequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New classes: `NextCharacterModel` and `LSTMTrainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5 = seq_len\n",
    "* 3 = batch\n",
    "* 10 = input_size\n",
    "* 20 = hidden_size\n",
    "\n",
    "* h0 = `(num_layers, batch_size, hidden_size)` = (2, 3, 20)\n",
    "\n",
    "nn.LSTM(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 sequence_length: int,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 dropout: float = 1.0) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_init = torch.zeros((1, hidden_size))\n",
    "        self.c_init = torch.zeros((1, hidden_size))\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = DenseLayer(hidden_size, output_size)\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "        \n",
    "    def _transform_hidden_batch(self, hidden: Tensor,\n",
    "                                batch_size: int,\n",
    "                                before_layer: bool) -> Tensor:\n",
    "        \n",
    "        if before_layer:\n",
    "            return (hidden\n",
    "                    .repeat(batch_size, 1)\n",
    "                    .view(batch_size, 1, self.hidden_size)\n",
    "                    .permute(1,0,2))\n",
    "        else:\n",
    "            return (hidden\n",
    "                    .permute(1,0,2)\n",
    "                    .mean(dim=0))         \n",
    "    \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        h_layer = self._transform_hidden_batch(self.h_init, batch_size, before_layer=True)\n",
    "        c_layer = self._transform_hidden_batch(self.c_init, batch_size, before_layer=True)\n",
    "        \n",
    "        x, (h_out, c_out) = self.lstm(x, (h_layer, c_layer))\n",
    "        \n",
    "        self.h_init, self.c_init = (\n",
    "            self._transform_hidden_batch(h_out, batch_size, before_layer=False).detach(),\n",
    "            self._transform_hidden_batch(c_out, batch_size, before_layer=False).detach()\n",
    "        )\n",
    "\n",
    "        x = self.fc(x)\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x) \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay = LSTMLayer(sequence_length=25,\n",
    "          input_size=62,\n",
    "          hidden_size=100,\n",
    "          output_size=128)\n",
    "\n",
    "x = torch.randn(32, 25, 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextCharacterModel(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 sequence_length: int = 25):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # In this model, we have only one layer, with the same output size as input_size\n",
    "        self.lstm = LSTMLayer(self.sequence_length, self.vocab_size, hidden_size, self.vocab_size)\n",
    "\n",
    "    def forward(self,\n",
    "                inputs: Tensor):\n",
    "        assert_dim(inputs, 3) # batch_size, sequence_length, vocab_size\n",
    "\n",
    "        out = self.lstm(inputs)       \n",
    "        \n",
    "        return out.permute(0, 2, 1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTrainer(PyTorchTrainer):\n",
    "    def __init__(self,\n",
    "                 model: NextCharacterModel,\n",
    "                 optim: Optimizer,\n",
    "                 criterion: _Loss):\n",
    "        super().__init__(model, optim, criterion)\n",
    "        self.vocab_size = self.model.vocab_size\n",
    "        self.max_len = self.model.sequence_length\n",
    "        \n",
    "    def fit(self,\n",
    "            data: str,\n",
    "            epochs: int=10,\n",
    "            eval_every: int=1,\n",
    "            batch_size: int=32,\n",
    "            seed: int = 121718)-> None:\n",
    "        \n",
    "        self.data = data\n",
    "        self.train_data, self.test_data = self._train_test_split_text()\n",
    "        self.chars = list(set(self.data))\n",
    "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        losses = deque(maxlen=50)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "\n",
    "            batch_generator = self.generate_batches_next_char(batch_size)\n",
    "\n",
    "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "\n",
    "                self.optim.zero_grad()                \n",
    "                outputs = self.model(X_batch)\n",
    "\n",
    "                loss = self.loss(outputs, y_batch)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                print(loss.item())\n",
    "                \n",
    "                self.optim.step()    \n",
    "\n",
    "            if (e+1) % eval_every == 0:\n",
    "\n",
    "                X_test, y_test = self.generate_test_data()\n",
    "            \n",
    "                test_preds = self.net.forward(X_test)\n",
    "                loss = self.net.loss.forward(test_preds, y_test)\n",
    "                print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
    "\n",
    "    def _train_test_split_text(self, pct=0.8) -> Tuple[str]:\n",
    "\n",
    "        n = len(self.data)\n",
    "        return self.data[:int(n * pct)], self.data[int(n * pct):]\n",
    "\n",
    "    def generate_batches_next_char(self,\n",
    "                                   batch_size: int) -> Tuple[Tensor]:\n",
    "        N = len(self.train_data)\n",
    "        # add batch size\n",
    "        for ii in range(0, N, batch_size):\n",
    "\n",
    "            features_tensors = []\n",
    "            target_indices = []\n",
    "\n",
    "            for char in range(batch_size):\n",
    "\n",
    "                features_str, target_str =\\\n",
    "                 self.train_data[ii+char:ii+char+self.max_len],\\\n",
    "                 self.train_data[ii+char+1:ii+char+self.max_len+1]\n",
    "\n",
    "                features_array = self._string_to_one_hot_array(features_str)\n",
    "                target_indices_seq = [self.char_to_idx[char] for char in target_str]\n",
    "\n",
    "                features_tensors.append(features_array)\n",
    "                target_indices.append(target_indices_seq)\n",
    "#             import pdb; pdb.set_trace()\n",
    "            yield torch.stack(features_tensors), torch.LongTensor(target_indices)\n",
    "\n",
    "    def _string_to_one_hot_array(self, input_string: str) -> Tuple[Tensor]:\n",
    "\n",
    "        ind = [self.char_to_idx[ch] for ch in input_string]\n",
    "\n",
    "        array = self._one_hot_text_data(ind)\n",
    "\n",
    "        return array\n",
    "\n",
    "    def _one_hot_text_data(self,\n",
    "                           sequence: List):\n",
    "\n",
    "        sequence_length = len(sequence)\n",
    "        batch = torch.zeros(sequence_length, self.vocab_size)\n",
    "        for i in range(sequence_length):\n",
    "            batch[i, sequence[i]] = 1.0\n",
    "\n",
    "        return Tensor(batch)\n",
    "\n",
    "    def generate_test_data(self) -> Tuple[Tensor]:\n",
    "\n",
    "        features_str, target_str = self.test_data[:-1], self.test_data[1:]\n",
    "\n",
    "        X_tensors = []\n",
    "        y_tensors = []\n",
    "\n",
    "        N = len(self.test_data)\n",
    "\n",
    "        for start in range(0, N, self.max_len):\n",
    "\n",
    "            features_str, target_str =\\\n",
    "             self.test_data[start:start+self.max_len],\\\n",
    "             self.test_data[start+1:start+self.max_len+1]\n",
    "\n",
    "            features_array, target_array =\\\n",
    "                self._string_to_one_hot_array(features_str),\\\n",
    "                self._string_to_one_hot_array(target_str)\n",
    "\n",
    "            X_tensors.append(features_array)\n",
    "            y_tensors.append(target_array)\n",
    "\n",
    "        return torch.stack(X_tensors), torch.stack(y_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('data/input.txt', 'r').read()\n",
    "vocab_size = len(set(data))\n",
    "model = NextCharacterModel(vocab_size, hidden_size=vocab_size, sequence_length=50)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trainer = LSTMTrainer(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_trainer.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "* Write code to generate next character from this.\n",
    "* Write early stopping code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning with Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, filter_size, \n",
    "                                       padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.deconv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 hidden_dim: int = 28):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh())\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True)\n",
    "        \n",
    "        self.dense1 = DenseLayer(7 * 28 * 28, hidden_dim, activation=nn.Tanh())\n",
    "        self.dense2 = DenseLayer(hidden_dim, 7 * 28 * 28, activation=nn.Tanh())\n",
    "        \n",
    "        self.conv3 = ConvLayer(7, 14, 5, activation=nn.Tanh()) \n",
    "        self.conv4 = ConvLayer(14, 1, 5, activation=nn.Tanh())         \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        encoding = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(encoding)\n",
    "        \n",
    "        x = x.view(-1, 7, 28, 28)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        return x, encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_train\n",
    "X_test = mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_auto = (X_train - X_train.min()) / (X_train.max() - X_train.min()) * 2 - 1\n",
    "X_test_auto = (X_test - X_train.min()) / (X_train.max() - X_train.min()) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(hidden_dim=28)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train_auto, X_train_auto,\n",
    "            X_test_auto, X_test_auto,\n",
    "            epochs=1,\n",
    "            batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstructed_images, image_representations = model(X_test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(ax,\n",
    "    t: Tensor):\n",
    "    n = t.detach().numpy()\n",
    "    ax.imshow(n.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20190504)\n",
    "a = np.random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "display_image(axarr[0], X_test[a])\n",
    "display_image(axarr[1], reconstructed_images[a])\n",
    "\n",
    "axarr[0].set_title(\"Original image\")\n",
    "axarr[1].set_title(\"Image reconstructed\\nfrom autoencoder\")\n",
    "\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off');\n",
    "\n",
    "f.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/03_autoencoder_example_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_result = TSNE(n_components=2, random_state=20190405).fit_transform(out[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tsne_df = pd.DataFrame({'tsne_dim_1': tsne_result[:,0], \n",
    "              'tsne_dim_2': tsne_result[:,1],\n",
    "              'category': mnist_testset.test_labels})\n",
    "\n",
    "# tsne_df.plot.scatter(x='tsne_dim_1', y='tsne_dim_2')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "ax.set_title('''10000 observations from MNIST test set, colored by their actual digit. \n",
    "Locations are the result of reducing the 28 values from hidden layer of the convolutional\n",
    "autoencoder - trained without labels - down to two dimensions using t-SNE.''')\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['tsne_dim_1'], group['tsne_dim_2'], marker='o', label=name)\n",
    "ax.legend()\n",
    "# fig.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/00_tsne.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder with hidden dimension 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just out of curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Autoencoder2(hidden_dim=2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainer = PyTorchTrainer(model2, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train_auto, X_train_auto, \n",
    "            X_test_auto, X_test_auto,\n",
    "            epochs=1,\n",
    "            eval_every=1,\n",
    "            batch_size=60,\n",
    "            final_lr_exp = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images, image_representations = model2(X_test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "display_image(axarr[0], X_test[3765])\n",
    "display_image(axarr[1], reconstructed_images[3765])\n",
    "\n",
    "axarr[0].set_title(\"Original image\")\n",
    "axarr[1].set_title(\"Image reconstructed\\nfrom autoencoder\")\n",
    "\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off');\n",
    "\n",
    "# f.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/03_autoencoder_example_image.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
