{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frameworks:\n",
    "\n",
    "* PyTorch first pass\n",
    "    * `Model` with `forward` method.\n",
    "    * Manual training loop\n",
    "* PyTorch second pass\n",
    "    * `Model` with `forward` method.\n",
    "    * `Trainer` class that takes in:\n",
    "        * `Model`\n",
    "        * `Optimizer`\n",
    "        * `_Loss`\n",
    "\n",
    "Models:\n",
    "\n",
    "* Boston dataset (used for testing)\n",
    "* MNIST Conv net\n",
    "* LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from typing import Tuple, List\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from lincoln.utils import permute_data, assert_dim\n",
    "\n",
    "from lincoln.pytorch.model import PyTorchModel\n",
    "from lincoln.pytorch.train import PyTorchTrainer\n",
    "from lincoln.pytorch.preprocessor import ConvNetPreprocessor\n",
    "\n",
    "torch.manual_seed(20190325);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Trainer` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Boston model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchLayer(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "def inference_mode(m: nn.Module):\n",
    "    m.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 neurons: int,\n",
    "                 dropout: float = 1.0,\n",
    "                 activation: nn.Module = None) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, neurons)\n",
    "        self.activation = activation\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        if inference:\n",
    "            self.apply(inference_mode)\n",
    "        \n",
    "        x = self.linear(x) # does weight multiplication + bias\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonModel(PyTorchModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 13,\n",
    "                 hidden_dropout: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = DenseLayer(13, hidden_size, \n",
    "                                 activation=nn.Tanh(),\n",
    "                                 dropout = hidden_dropout)\n",
    "        self.dense2 = DenseLayer(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        \n",
    "        assert_dim(x, 2)\n",
    "        \n",
    "        assert x.shape[1] == 13\n",
    "\n",
    "        x = self.dense1(x, inference)\n",
    "        return self.dense2(x, inference),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, optimizer, loss\n",
    "pytorch_boston_model = BostonModel(hidden_size=13, hidden_dropout=0.8)\n",
    "optimizer = optim.SGD(pytorch_boston_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 0 epochs was 437.0794982910156\n",
      "The loss after 10 epochs was 25.685544967651367\n",
      "The loss after 20 epochs was 21.339204788208008\n",
      "The loss after 30 epochs was 19.30413055419922\n",
      "The loss after 40 epochs was 19.5618839263916\n",
      "The loss after 50 epochs was 18.17092514038086\n",
      "The loss after 60 epochs was 18.57846450805664\n",
      "The loss after 70 epochs was 18.508407592773438\n",
      "The loss after 80 epochs was 16.80544662475586\n",
      "The loss after 90 epochs was 16.327821731567383\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(pytorch_boston_model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs=100,\n",
    "            eval_every=10,\n",
    "            final_lr_exp = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.740818977355957"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.pow(pytorch_boston_model(X_test, inference=True)[0] - y_test, 2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pytorch_boston_model(X_test)[0].view(-1)\n",
    "test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred.detach().numpy()\n",
    "test_actual = test_actual.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a1ed0f160>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(test_pred, test_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Transforms, using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1305,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/data.html\n",
    "train_dataset = MNIST(root='../mnist_data/',\n",
    "                      train=True, \n",
    "                      download=True,\n",
    "                      transform=img_transforms)\n",
    "\n",
    "test_dataset = MNIST(root='../mnist_data/',\n",
    "                     train=False, \n",
    "                     download=True,\n",
    "                     transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=60, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=60, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, filter_size, \n",
    "                              padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.conv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_ConvNet(PyTorchModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh(),\n",
    "                               dropout=0.8)\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True,\n",
    "                               dropout=0.8)\n",
    "        self.dense1 = DenseLayer(28 * 28 * 7, 32, activation=nn.Tanh(),\n",
    "                                 dropout=0.8)\n",
    "        self.dense2 = DenseLayer(32, 10)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using only `Dataloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 0 epochs was 0.085\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(train_dataloader = train_loader,        \n",
    "            test_dataloader = test_loader,\n",
    "            epochs=1,\n",
    "            eval_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy using only the `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model):\n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    for ii, (X_batch, y_batch) in enumerate(test_loader):\n",
    "        output = model(X_batch)[0]\n",
    "        accuracy_batch = (torch.max(output, dim=1)[1] == y_batch).type(torch.float32).mean().item()\n",
    "        accuracies.append(accuracy_batch)\n",
    "    return torch.Tensor(accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9658)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without using `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ((train_dataset.train_data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081\n",
    "mnist_test = ((test_dataset.test_data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.4236), tensor(2.8221), tensor(-0.4236), tensor(2.8221))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.min(), mnist_train.max(), mnist_test.min(), mnist_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 0 epochs was 0.11979854851961136\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train=mnist_train, y_train=train_dataset.train_labels, \n",
    "            X_test=mnist_test, y_test=test_dataset.test_labels,     \n",
    "            epochs=1,\n",
    "            eval_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_no_dataloader(model, mnist_test):\n",
    "    model.eval()\n",
    "    output = model(mnist_test)[0]\n",
    "    return (torch.max(output, dim=1)[1] == test_dataset.test_labels).type(torch.float32).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659000039100647"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_no_dataloader(model, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~98% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working backwards:\n",
    "\n",
    "* Want a character level model - predict next char."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to do it?\n",
    "\n",
    "Pass in sequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New classes: `NextCharacterModel` and `LSTMTrainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5 = seq_len\n",
    "* 3 = batch\n",
    "* 10 = input_size\n",
    "* 20 = hidden_size\n",
    "\n",
    "* h0 = `(num_layers, batch_size, hidden_size)` = (2, 3, 20)\n",
    "\n",
    "nn.LSTM(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 sequence_length: int,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 dropout: float = 1.0) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_init = torch.zeros((1, hidden_size))\n",
    "        self.c_init = torch.zeros((1, hidden_size))\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = DenseLayer(hidden_size, output_size)\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "        \n",
    "    def _transform_hidden_batch(self, hidden: Tensor,\n",
    "                                batch_size: int,\n",
    "                                before_layer: bool) -> Tensor:\n",
    "        \n",
    "        if before_layer:\n",
    "            return (hidden\n",
    "                    .repeat(batch_size, 1)\n",
    "                    .view(batch_size, 1, self.hidden_size)\n",
    "                    .permute(1,0,2))\n",
    "        else:\n",
    "            return (hidden\n",
    "                    .permute(1,0,2)\n",
    "                    .mean(dim=0))         \n",
    "    \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        h_layer = self._transform_hidden_batch(self.h_init, batch_size, before_layer=True)\n",
    "        c_layer = self._transform_hidden_batch(self.c_init, batch_size, before_layer=True)\n",
    "        \n",
    "        x, (h_out, c_out) = self.lstm(x, (h_layer, c_layer))\n",
    "        \n",
    "        self.h_init, self.c_init = (\n",
    "            self._transform_hidden_batch(h_out, batch_size, before_layer=False).detach(),\n",
    "            self._transform_hidden_batch(c_out, batch_size, before_layer=False).detach()\n",
    "        )\n",
    "\n",
    "        x = self.fc(x)\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x) \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay = LSTMLayer(sequence_length=25,\n",
    "          input_size=62,\n",
    "          hidden_size=100,\n",
    "          output_size=128)\n",
    "\n",
    "x = torch.randn(32, 25, 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextCharacterModel(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 sequence_length: int = 25):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # In this model, we have only one layer, with the same output size as input_size\n",
    "        self.lstm = LSTMLayer(self.sequence_length, self.vocab_size, hidden_size, self.vocab_size)\n",
    "\n",
    "    def forward(self,\n",
    "                inputs: Tensor):\n",
    "        assert_dim(inputs, 3) # batch_size, sequence_length, vocab_size\n",
    "\n",
    "        out = self.lstm(inputs)       \n",
    "        \n",
    "        return out.permute(0, 2, 1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTrainer(PyTorchTrainer):\n",
    "    def __init__(self,\n",
    "                 model: NextCharacterModel,\n",
    "                 optim: Optimizer,\n",
    "                 criterion: _Loss):\n",
    "        super().__init__(model, optim, criterion)\n",
    "        self.vocab_size = self.model.vocab_size\n",
    "        self.max_len = self.model.sequence_length\n",
    "        \n",
    "    def fit(self,\n",
    "            data: str,\n",
    "            epochs: int=10,\n",
    "            eval_every: int=1,\n",
    "            batch_size: int=32,\n",
    "            seed: int = 121718)-> None:\n",
    "        \n",
    "        self.data = data\n",
    "        self.train_data, self.test_data = self._train_test_split_text()\n",
    "        self.chars = list(set(self.data))\n",
    "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        losses = deque(maxlen=50)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "\n",
    "            batch_generator = self.generate_batches_next_char(batch_size)\n",
    "\n",
    "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "\n",
    "                self.optim.zero_grad()                \n",
    "                outputs = self.model(X_batch)\n",
    "\n",
    "                loss = self.loss(outputs, y_batch)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                print(loss.item())\n",
    "                \n",
    "                self.optim.step()    \n",
    "\n",
    "            if (e+1) % eval_every == 0:\n",
    "\n",
    "                X_test, y_test = self.generate_test_data()\n",
    "            \n",
    "                test_preds = self.net.forward(X_test)\n",
    "                loss = self.net.loss.forward(test_preds, y_test)\n",
    "                print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
    "\n",
    "    def _train_test_split_text(self, pct=0.8) -> Tuple[str]:\n",
    "\n",
    "        n = len(self.data)\n",
    "        return self.data[:int(n * pct)], self.data[int(n * pct):]\n",
    "\n",
    "    def generate_batches_next_char(self,\n",
    "                                   batch_size: int) -> Tuple[Tensor]:\n",
    "        N = len(self.train_data)\n",
    "        # add batch size\n",
    "        for ii in range(0, N, batch_size):\n",
    "\n",
    "            features_tensors = []\n",
    "            target_indices = []\n",
    "\n",
    "            for char in range(batch_size):\n",
    "\n",
    "                features_str, target_str =\\\n",
    "                 self.train_data[ii+char:ii+char+self.max_len],\\\n",
    "                 self.train_data[ii+char+1:ii+char+self.max_len+1]\n",
    "\n",
    "                features_array = self._string_to_one_hot_array(features_str)\n",
    "                target_indices_seq = [self.char_to_idx[char] for char in target_str]\n",
    "\n",
    "                features_tensors.append(features_array)\n",
    "                target_indices.append(target_indices_seq)\n",
    "#             import pdb; pdb.set_trace()\n",
    "            yield torch.stack(features_tensors), torch.LongTensor(target_indices)\n",
    "\n",
    "    def _string_to_one_hot_array(self, input_string: str) -> Tuple[Tensor]:\n",
    "\n",
    "        ind = [self.char_to_idx[ch] for ch in input_string]\n",
    "\n",
    "        array = self._one_hot_text_data(ind)\n",
    "\n",
    "        return array\n",
    "\n",
    "    def _one_hot_text_data(self,\n",
    "                           sequence: List):\n",
    "\n",
    "        sequence_length = len(sequence)\n",
    "        batch = torch.zeros(sequence_length, self.vocab_size)\n",
    "        for i in range(sequence_length):\n",
    "            batch[i, sequence[i]] = 1.0\n",
    "\n",
    "        return Tensor(batch)\n",
    "\n",
    "    def generate_test_data(self) -> Tuple[Tensor]:\n",
    "\n",
    "        features_str, target_str = self.test_data[:-1], self.test_data[1:]\n",
    "\n",
    "        X_tensors = []\n",
    "        y_tensors = []\n",
    "\n",
    "        N = len(self.test_data)\n",
    "\n",
    "        for start in range(0, N, self.max_len):\n",
    "\n",
    "            features_str, target_str =\\\n",
    "             self.test_data[start:start+self.max_len],\\\n",
    "             self.test_data[start+1:start+self.max_len+1]\n",
    "\n",
    "            features_array, target_array =\\\n",
    "                self._string_to_one_hot_array(features_str),\\\n",
    "                self._string_to_one_hot_array(target_str)\n",
    "\n",
    "            X_tensors.append(features_array)\n",
    "            y_tensors.append(target_array)\n",
    "\n",
    "        return torch.stack(X_tensors), torch.stack(y_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('data/input.txt', 'r').read()\n",
    "vocab_size = len(set(data))\n",
    "model = NextCharacterModel(vocab_size, hidden_size=vocab_size, sequence_length=50)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trainer = LSTMTrainer(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_trainer.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "* Write code to generate next character from this.\n",
    "* Write early stopping code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning with Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, filter_size, \n",
    "                                       padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.deconv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 hidden_dim: int = 28):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh())\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True)\n",
    "        \n",
    "        self.dense1 = DenseLayer(7 * 28 * 28, hidden_dim, activation=nn.Tanh())\n",
    "        self.dense2 = DenseLayer(hidden_dim, 7 * 28 * 28, activation=nn.Tanh())\n",
    "        \n",
    "        self.conv3 = ConvLayer(7, 14, 5, activation=nn.Tanh()) \n",
    "        self.conv4 = ConvLayer(14, 1, 5, activation=nn.Tanh())         \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        encoding = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(encoding)\n",
    "        \n",
    "        x = x.view(-1, 7, 28, 28)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        return x, encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_train\n",
    "X_test = mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_auto = (X_train - X_train.min()) / (X_train.max() - X_train.min()) * 2 - 1\n",
    "X_test_auto = (X_test - X_train.min()) / (X_train.max() - X_train.min()) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 0 epochs was 0.0699353963136673\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(hidden_dim=28)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train_auto, X_train_auto,\n",
    "            X_test_auto, X_test_auto,\n",
    "            epochs=1,\n",
    "            batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstructed_images, image_representations = model(X_test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(ax,\n",
    "    t: Tensor):\n",
    "    n = t.detach().numpy()\n",
    "    ax.imshow(n.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20190504)\n",
    "a = np.random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "display_image(axarr[0], X_test[a])\n",
    "display_image(axarr[1], reconstructed_images[a])\n",
    "\n",
    "axarr[0].set_title(\"Original image\")\n",
    "axarr[1].set_title(\"Image reconstructed\\nfrom autoencoder\")\n",
    "\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off');\n",
    "\n",
    "f.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/03_autoencoder_example_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_result = TSNE(n_components=2, random_state=20190405).fit_transform(out[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tsne_df = pd.DataFrame({'tsne_dim_1': tsne_result[:,0], \n",
    "              'tsne_dim_2': tsne_result[:,1],\n",
    "              'category': mnist_testset.test_labels})\n",
    "\n",
    "# tsne_df.plot.scatter(x='tsne_dim_1', y='tsne_dim_2')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "ax.set_title('''10000 observations from MNIST test set, colored by their actual digit. \n",
    "Locations are the result of reducing the 28 values from hidden layer of the convolutional\n",
    "autoencoder - trained without labels - down to two dimensions using t-SNE.''')\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['tsne_dim_1'], group['tsne_dim_2'], marker='o', label=name)\n",
    "ax.legend()\n",
    "# fig.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/00_tsne.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder with hidden dimension 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just out of curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Autoencoder2(hidden_dim=2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainer = PyTorchTrainer(model2, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train_auto, X_train_auto, \n",
    "            X_test_auto, X_test_auto,\n",
    "            epochs=1,\n",
    "            eval_every=1,\n",
    "            batch_size=60,\n",
    "            final_lr_exp = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images, image_representations = model2(X_test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "display_image(axarr[0], X_test[3765])\n",
    "display_image(axarr[1], reconstructed_images[3765])\n",
    "\n",
    "axarr[0].set_title(\"Original image\")\n",
    "axarr[1].set_title(\"Image reconstructed\\nfrom autoencoder\")\n",
    "\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off');\n",
    "\n",
    "# f.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/03_autoencoder_example_image.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
